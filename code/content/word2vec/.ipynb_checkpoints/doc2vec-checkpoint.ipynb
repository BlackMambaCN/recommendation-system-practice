{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然word2vec可以表示词之间的语义。但当我们做类似情感分析问题时，需要考虑Sentence/Document的向量化表示。虽然我们可以直接将Sentence/Document的词向量取均值作为句子或段落的向量表示，但这样做显然忽略了词序。\n",
    "\n",
    "如何采用一个向量可以代表段落或文档的语义和词序呢？\n",
    "\n",
    "Quoc Le和Tomas Mikolov提出了Doc2Vec方法，可以通过计算距离找到段落或文档的相似性；可以用于文本聚类或有监督方法来进行文本分类。\n",
    "\n",
    "与word2vec一样，Doc2vec也有两种模型，分别是 Distributed Memory（DM）和 Distributed Bag of Words（DBOW）。DM模型是给定上下文和文档向量的情况下预测单词的概率，DBOW模型在给定文档向量的情况下预测文档中一组随机单词的概率。其中，在一个文档训练过程中，文档向量共享，这意味着在预测单词概率时，使用了整个文档的语义。\n",
    "\n",
    "<img src=\"./imgs/doc2vec.png\" width = \"400\" height = \"400\" />\n",
    "\n",
    "由上图可知，Doc2vec的DM模型与word2vec模型的CBOW很像，不同点是输入层多了一个段落id。每个段落都被映射到向量空间中，然后用段落矩阵的一列表示。每个单词同样也被映射到向量空间，用矩阵的一列表示，然后将段落向量和词向量级联或平均求特征，预测句子中的下一个单词。\n",
    "\n",
    "这个段落向量也可以认为是一个单词，作用相当于上下文的记忆单元或这个段落的主题向量。这种训练方法为Distributed Memory Model of Paragraph Vectors(PV-DM)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
