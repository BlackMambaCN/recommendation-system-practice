{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.准备文档数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"Sugar sugar sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
    "doc2 = \"sugar My father spends a lot of time driving my sister around to dance practice.\"\n",
    "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
    "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never se\\\n",
    "ems to drive my sister to do better.\"\n",
    "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
    "\n",
    "mydoc = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.数据清洗和预处理，包括移除标点符号，停用词和标准化语料库（Lemmatize，将英文词归元）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n[['sugar', 'bad', 'consume', 'sister', 'like', 'sugar', 'father'], \\n ['father','spends','lot','time','driving','sister','around','dance','practice'],...\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_words(doc):\n",
    "    \"\"\" 数据清洗 \"\"\"\n",
    "    stop = set(stopwords.words('english')) # 停止词\n",
    "    exclude = set(string.punctuation) # 标点符号\n",
    "    lemma = WordNetLemmatizer() # 词性还原\n",
    "    \n",
    "    clean_stopwords = \" \".join([c for c in doc.lower().split() if c not in stop])\n",
    "    clean_exclude = \"\".join(c for c in clean_stopwords if c not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in clean_exclude.split())\n",
    "    return normalized\n",
    "\n",
    "clean_mydoc = [clean_words(doc).split() for doc in mydoc]\n",
    "'''\n",
    "[['sugar', 'bad', 'consume', 'sister', 'like', 'sugar', 'father'], \n",
    " ['father','spends','lot','time','driving','sister','around','dance','practice'],...\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.将预料转化为Document-Term矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndoc_item_matrix:\\n[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)],\\n[(2, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],...\\n这里第一行的(5, 1)代表sugar出现一次。\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  创建预料词典，每个词都给予一个索引\n",
    "dictionary = corpora.Dictionary(clean_mydoc)\n",
    "\n",
    "# 将文本变成词袋矩阵\n",
    "doc_item_matrix = [dictionary.doc2bow(doc) for doc in clean_mydoc]\n",
    "'''\n",
    "doc_item_matrix:\n",
    "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)],\n",
    "[(2, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],...\n",
    "这里第一行的(5, 2)可能代表sugar出现2次。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.构建一个LDA对象，使用DT矩阵进行训练。采用训练好的模型，对新文档做主题分布的推断。\n",
    "\n",
    "ldamodel = LdaModel(text, num_topics=10, id2word=dictionary, passes=20)\n",
    "\n",
    "参数:\n",
    "    \n",
    "    - text 词袋，这里已经表示成DT矩阵了\n",
    "    - num_topics 主题数\n",
    "    - id2word 词典\n",
    "    - passes 训练的轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# 在 DT 矩阵上运行和训练 LDA 模型\n",
    "ldamodel = lda(doc_item_matrix, num_topics=3, id2word=dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.062*\"father\" + 0.062*\"sister\" + 0.062*\"driving\"'),\n",
       " (1, '0.150*\"sugar\" + 0.037*\"cause\" + 0.037*\"doctor\"'),\n",
       " (2, '0.057*\"sister\" + 0.057*\"father\" + 0.057*\"pressure\"')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=3, num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工程实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import sys \n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA(object):\n",
    "    def __init__(self, topics=10,\n",
    "                worker=3,\n",
    "                pretrained_model=None,\n",
    "                dictionary=None):\n",
    "        \"\"\" lda模型训练初始化\n",
    "        Args:\n",
    "            topics -- 指定主题个数\n",
    "            worker -- 并行化参数，一般为core数量减一\n",
    "            pretrained_model -- 预训练模型，由于支持在线更新，所以可以加载上次训练的模型\n",
    "            dictionary -- 训练时词需要转换成ID，所以跟模型配套有一个ID映射的字典\n",
    "        Example:\n",
    "            >>> lda = LDA(topics = 20, worker = 2, \n",
    "                          pretrained_model = model_file, \n",
    "                          dictionary = dictionary_file)\n",
    "            >>> corpus = read_file(corpus_file) # [['word1', 'word2'], ['word3', 'word4']]\n",
    "            >>> lda.update(corpus)\n",
    "            >>> lda.save(model_file, dictionary_file)\n",
    "            >>> topics = lda.inference(['word5', 'word6'])\n",
    "        \"\"\"\n",
    "        \n",
    "        self._topics = topics\n",
    "        self._workers = worker\n",
    "        self._model = None\n",
    "        self._common_dictionary = None\n",
    "        \n",
    "        if pretrained_model and dictionary:\n",
    "            self._model = LdaModel.load(pretrained_model)\n",
    "            self._common_dictionary = Dictionary.load(dictionary)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考\n",
    "\n",
    "深入浅出讲解LDA主题模型（一）\n",
    "\n",
    "https://blog.csdn.net/Love_wanling/article/details/72872180\n",
    "\n",
    "主题模型 LDA 入门（附 Python 代码）\n",
    "\n",
    "https://blog.csdn.net/selinda001/article/details/80446766\n",
    "\n",
    "NLP Lemmatisation（词性还原） 和 Stemming（词干提取） NLTK pos_tag word_tokenize\n",
    "\n",
    "https://blog.csdn.net/qq_16234613/article/details/79430381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
